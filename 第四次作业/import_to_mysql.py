import os
import pandas as pd
import pymysql
import chardet

# ========== 1ï¸âƒ£ åŸºæœ¬é…ç½® ==========
DATA_DIR = r"C:\Users\xze97\Desktop\Programming\python\lab\ç¬¬å››æ¬¡ä½œä¸š\data"

DB_CONFIG = {
    "host": "localhost",
    "user": "root",
    "password": "123456",  # æ”¹æˆä½ è‡ªå·±çš„
    "database": "university_data",
    "charset": "utf8mb4"
}

# ========== 2ï¸âƒ£ å»ºç«‹æ•°æ®åº“è¿æ¥ ==========
try:
    conn = pymysql.connect(**DB_CONFIG)
    cursor = conn.cursor()
    print("âœ… æˆåŠŸè¿æ¥ MySQL æ•°æ®åº“")
except Exception as e:
    print("âŒ æ— æ³•è¿æ¥æ•°æ®åº“:", e)
    exit()

# ========== 3ï¸âƒ£ åˆ—åæ˜ å°„ï¼ˆæ ¹æ®çœŸå®æ–‡ä»¶ï¼‰ ==========
col_map = {
    "Institution": ["Institutions", "Institution", "University"],
    "Web of Science Documents": ["Web of Science Documents"],
    "Cites": ["Cites", "Citations"],
    "Cites/Paper": ["Cites/Paper", "Cites per paper"],
    "Top Papers": ["Top Papers"]
}

total_files = 0
total_rows = 0
skipped_files = []

# ========== 4ï¸âƒ£ éå† CSV æ–‡ä»¶ ==========
for filename in os.listdir(DATA_DIR):
    if not filename.endswith(".csv"):
        continue
    total_files += 1
    subject = os.path.splitext(filename)[0]
    filepath = os.path.join(DATA_DIR, filename)

    # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç 
    with open(filepath, 'rb') as f:
        enc = chardet.detect(f.read())['encoding'] or 'utf-8'

    try:
        # è·³è¿‡ç¬¬ä¸€è¡Œè¯´æ˜æ€§æ–‡å­—
        df = pd.read_csv(filepath, encoding=enc, skiprows=1)
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å– {filename}: {e}")
        skipped_files.append(filename)
        continue

    # å»é™¤å¤šä½™ç©ºæ ¼
    df.columns = [col.strip() for col in df.columns]

    # å¤„ç†å¯èƒ½å­˜åœ¨çš„ç¼–å·åˆ—ï¼ˆç¬¬ä¸€ä¸ªåˆ—åä¸ºç©ºæˆ–ä¸ºåºå·ï¼‰
    if df.columns[0] == '' or 'Unnamed' in df.columns[0]:
        df.drop(df.columns[0], axis=1, inplace=True)

    # è‡ªåŠ¨åŒ¹é…åˆ—å
    rename_dict = {}
    for std_col, possible_names in col_map.items():
        for name in df.columns:
            if name.strip() in possible_names:
                rename_dict[name] = std_col
                break
    df.rename(columns=rename_dict, inplace=True)

    # æ£€æŸ¥åˆ—æ˜¯å¦é½å…¨
    required_cols = list(col_map.keys())
    if not all(col in df.columns for col in required_cols):
        print(f"âš ï¸ {filename} çš„åˆ—åä¸åŒ¹é…ï¼Œè·³è¿‡")
        skipped_files.append(filename)
        continue

    # æ’å…¥æ•°æ®åº“
    print(f"ğŸ“‚ æ­£åœ¨å¯¼å…¥ {filename} ({len(df)} æ¡è®°å½•)...")
    success = 0
    for _, row in df.iterrows():
        try:
            sql = """
                INSERT INTO disciplines (subject, institution, `rank`, wos_documents, cites, cites_per_paper, top_papers)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            # ç”±äºæ²¡æœ‰ Rank åˆ—ï¼Œç”¨è‡ªåŠ¨é€’å¢åºå·ä»£æ›¿
            cursor.execute(sql, (
                subject,
                row["Institution"],
                int(_ + 1),  # rank = è¡Œå·
                int(row["Web of Science Documents"]),
                int(row["Cites"]),
                float(row["Cites/Paper"]),
                int(row["Top Papers"])
            ))
            success += 1
        except Exception as e:
            print(f"âŒ æ’å…¥å¤±è´¥ ({filename}): {e}")

    conn.commit()
    print(f"âœ… {filename} å¯¼å…¥å®Œæˆ ({success}/{len(df)})")
    total_rows += success

# ========== 5ï¸âƒ£ ç»“æŸå¤„ç† ==========
cursor.close()
conn.close()

print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¯¼å…¥å®Œæˆï¼")
print(f"ğŸ“Š å…±å¤„ç†æ–‡ä»¶æ•°: {total_files}")
print(f"ğŸ“ˆ æˆåŠŸå¯¼å…¥è®°å½•: {total_rows}")
if skipped_files:
    print(f"âš ï¸ ä»¥ä¸‹æ–‡ä»¶è¢«è·³è¿‡: {', '.join(skipped_files)}")
else:
    print("âœ… æ‰€æœ‰æ–‡ä»¶å‡æˆåŠŸå¯¼å…¥")
