from selenium import webdriver
from selenium.webdriver.edge.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import os

# ========== 1. é…ç½® Edge æµè§ˆå™¨ ==========
edge_options = Options()
edge_options.add_argument("--start-maximized")
edge_options.add_argument("--disable-blink-features=AutomationControlled")

driver = webdriver.Edge(options=edge_options)
wait = WebDriverWait(driver, 60)

# ========== 2. æ‰“å¼€ ESI é¡µé¢ ==========
url = "https://esi.clarivate.com/IndicatorsAction.action?app=esi&Init=Yes"
driver.get(url)
input("ğŸ‘‰ è¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆ CERNET ç™»å½•å¹¶è¿›å…¥ ESI ä¸»é¡µé¢åï¼ŒæŒ‰å›è½¦ç»§ç»­...")

# ========== 3. åˆ›å»ºä¿å­˜ç›®å½• ==========
save_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "esi_results")
os.makedirs(save_dir, exist_ok=True)

# ========== 4. å®šä¹‰è¡¨æ ¼æŠ“å–å‡½æ•° ==========
def scrape_table(field_name):
    try:
        # 1) ç­‰åˆ°è¡¨æ ¼ä¸»ä½“å‡ºç°ï¼ˆåŠ¨æ€ idï¼‰
        tbody_sel = "tbody[id^='gridview-'][id$='-body']"
        table_body = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, tbody_sel))
        )

        # 2) å®šä½æ»šåŠ¨å®¹å™¨ï¼ˆåŠ¨æ€ id / ç±»åå…œåº•ï¼‰
        try:
            scroll_container = driver.find_element(By.CSS_SELECTOR, "div[id^='gridview-']")
        except:
            scroll_container = driver.find_element(By.CSS_SELECTOR, "div.x-grid-view")

        # 3) å¢é‡æ»šåŠ¨ & å»é‡ç´¯è®¡
        seen_keys = set()
        all_rows = []

        def harvest_visible_rows():
            rows = driver.find_elements(By.CSS_SELECTOR, f"{tbody_sel} tr")
            added = 0
            for r in rows:
                # å…ˆå–ç¨³å®šçš„è¡Œæ ‡è¯†
                key = r.get_attribute("id") or r.get_attribute("data-recordid")
                tds = r.find_elements(By.TAG_NAME, "td")
                if not key:
                    # å…œåº•ï¼šç”¨å‰ä¸‰åˆ—å†…å®¹åšå»é‡é”®ï¼ˆæ’å+æœºæ„+å›½å®¶ï¼‰
                    head = [td.text.strip() for td in tds[:3]]
                    key = "|".join(head)
                if key in seen_keys:
                    continue
                seen_keys.add(key)
                values = [td.text.strip() for td in tds]
                if values:
                    all_rows.append(values)
                    added += 1
            return added

        # å…ˆæ”¶é›†é¦–å±
        harvest_visible_rows()

        # æ»šåŠ¨å‚æ•°
        stuck_rounds = 0
        prev_top = -1

        while True:
            # è¯»å–å½“å‰æ»šåŠ¨ä½ç½®ä¸æœ€å¤§å€¼
            cur_top = driver.execute_script("return arguments[0].scrollTop;", scroll_container)
            max_top = driver.execute_script("return arguments[0].scrollHeight - arguments[0].clientHeight;", scroll_container)

            # å‘ä¸‹æ»šåŠ¨ä¸€ä¸ªè§†çª—é«˜åº¦ï¼ˆç•¥å°äº 1 å±ï¼Œè§¦å‘åŠ è½½ï¼‰
            driver.execute_script(
                "arguments[0].scrollTop = arguments[0].scrollTop + arguments[0].clientHeight*0.9;",
                scroll_container
            )
            time.sleep(0.5)

            # é‡‡é›†å½“å‰å±çš„è¡Œ
            added_now = harvest_visible_rows()

            # è¿›åº¦åˆ¤æ–­
            new_top = driver.execute_script("return arguments[0].scrollTop;", scroll_container)
            if new_top == prev_top:
                stuck_rounds += 1
            else:
                stuck_rounds = 0
                prev_top = new_top

            # åˆ°åº• or å¤šæ¬¡ä¸å†æ»šåŠ¨ï¼Œåˆ™å†è¡¥é‡‡ä¸€æ¬¡åé€€å‡º
            if new_top >= max_top or stuck_rounds >= 3:
                time.sleep(0.5)
                harvest_visible_rows()
                break

        # 4) ä¿å­˜ Excel
        safe_name = field_name.replace(" ", "_").replace("/", "_")
        save_path = os.path.join(save_dir, f"{safe_name}.xlsx")
        df = pd.DataFrame(all_rows)
        df.to_excel(save_path, index=False, header=False)
        print(f"âœ… {field_name} é‡‡é›†å®Œæˆï¼šå…± {len(all_rows)} è¡Œï¼Œå·²ä¿å­˜åˆ° {save_path}")

    except Exception as e:
        print(f"âŒ æŠ“å– {field_name} å¤±è´¥: {e}")

# ========== 5. ä¸»å¾ªç¯ ==========
while True:
    field = input("\nğŸ‘‰ æ‰‹åŠ¨åˆ‡æ¢å­¦ç§‘åï¼Œåœ¨è¿™é‡Œè¾“å…¥å­¦ç§‘åç§°ï¼ˆæˆ–è¾“å…¥ q é€€å‡ºï¼‰: ").strip()
    if field.lower() == "q":
        print("ç¨‹åºç»“æŸï¼Œå…³é—­æµè§ˆå™¨ã€‚")
        break
    scrape_table(field)

driver.quit()
